{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final Project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOIa6wYnA5GK9TUS/f03qMh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jon85514/nlp-harrypotter-novel-generator/blob/main/Final_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKGmV7v3tARs"
      },
      "source": [
        "# README\n",
        "\n",
        "Please go to ***Edit > Notebook Settings *** and select the GPU.\n",
        "\n",
        "Since gpt2 and colab have a bug, we cannot put all file in the same directory.\n",
        "\n",
        "Our dataset **HarryPotter.txt** has to be placed under drive/MyDrive, upload from colab or google drive are both works.\n",
        "\n",
        "After placing **HarryPotter.txt** then the code can run sucessfully."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6uaCbzzdwVAp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6253e9b-0b41-45ed-ec61-2941f74cb5c3"
      },
      "source": [
        "%tensorflow_version 1.x        \n",
        "!pip install -q gpt-2-simple   \n",
        "import gpt_2_simple as gpt2\n",
        "from google.colab import files\n",
        "from datetime import datetime"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5MwCZunyruQ"
      },
      "source": [
        "Chose GPT2 model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PwJypcjPf8UR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db1af46d-ef1a-44af-9b5a-f5ea17d12222"
      },
      "source": [
        "model = \"124M\" #@param[\"124M\",\"355M\"]\n",
        "\n",
        "gpt2.download_gpt2(model_name=model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fetching checkpoint: 1.05Mit [00:00, 377Mit/s]                                                      \n",
            "Fetching encoder.json: 1.05Mit [00:00, 109Mit/s]                                                    \n",
            "Fetching hparams.json: 1.05Mit [00:00, 560Mit/s]                                                    \n",
            "Fetching model.ckpt.data-00000-of-00001: 498Mit [00:04, 116Mit/s]                                   \n",
            "Fetching model.ckpt.index: 1.05Mit [00:00, 263Mit/s]                                                \n",
            "Fetching model.ckpt.meta: 1.05Mit [00:00, 207Mit/s]                                                 \n",
            "Fetching vocab.bpe: 1.05Mit [00:00, 145Mit/s]                                                       \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJ3zsB6ty09m"
      },
      "source": [
        "GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4FY1HuAX2Hg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48013820-e7bc-4976-d773-a01eb521cc67"
      },
      "source": [
        "#make sure its using GPU\n",
        "#Mac :((\n",
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fri Dec  4 20:43:05 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.45.01    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   73C    P8    11W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U50Wr_Zny4uS"
      },
      "source": [
        "Please enter the authenticate code that provided by the link and connect to drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWWOJZHjgs8j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c673ad3c-c3c7-4da0-815d-bb142e29ca71"
      },
      "source": [
        "#connect to google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IC__xM1LziBU"
      },
      "source": [
        "Tried to copy **HarryPotter.txt** from  \n",
        "\n",
        "*/content/drive/My Drive/*\n",
        "\n",
        "to\n",
        "\n",
        "*/content/drive/My Drive/Colab/cs662/Final Project/*\n",
        "\n",
        "However the function in gpt_2.py did not work well:\n",
        "\n",
        "```\n",
        "def copy_file_from_gdrive(file_path):\n",
        "    \"\"\"Copies a file from a mounted Google Drive.\"\"\"\n",
        "    is_mounted()\n",
        "\n",
        "    shutil.copyfile(\"/content/drive/My Drive/\" + file_path, file_path)\n",
        "```\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLwHWQ7A24Pn"
      },
      "source": [
        "my_path = '/Colab/cs662/Final Project/' \n",
        "# not using my_path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puq4iC6vUAHc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f17e1d4-eef5-400c-fcb2-5be27809c2b9"
      },
      "source": [
        "gpt2.mount_gdrive()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 38
        },
        "id": "VXF6_RxT_5NJ",
        "outputId": "1d74c99a-64b4-46cf-9535-e377af47b2e9"
      },
      "source": [
        "%%html\n",
        "<marquee style='width: 30%; color: black;'><b>Harry Potter</b></marquee>"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<marquee style='width: 30%; color: black;'><b>Harry Potter</b></marquee>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YBvXSy0001uj"
      },
      "source": [
        "After placing HarryPotter.txt under MyDrive, the under code should work well"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SiKSql_sg_GX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e042fdb6-3d7c-423f-f719-6a654c13f8fd"
      },
      "source": [
        "file = \"HarryPotter.txt\" #@param {type : \"string\"}\n",
        "name = file[0:-4]\n",
        "# gpt2.copy_file_from_gdrive(my_path+file) \n",
        "# gpt_2.py issues: https://github.com/minimaxir/gpt-2-simple/issues/226\n",
        "# gpt2 cannot copy any file form other directory expect My Drive\n",
        "gpt2.copy_file_from_gdrive(file) \n",
        "print(\"file name: \" + file )\n",
        "print(\"Name: \" + name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "file name: HarryPotter.txt\n",
            "Name: HarryPotter\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eEannN1x1EaF"
      },
      "source": [
        "## Start finetune"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWTHUcjhigKi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2cff5465-92ed-4390-e72a-8fb77110db19"
      },
      "source": [
        "sess = gpt2.start_tf_sess()\n",
        "gpt2.finetune(sess,\n",
        "              dataset = file, #chose HarryPotter.txt\n",
        "              steps=500, # train 500 steps\n",
        "              model_name=model, #chose the model\n",
        "              combine=50000,\n",
        "              batch_size=1,\n",
        "              # learning_rate=0.00002,\n",
        "              # accumulate_gradients=1,\n",
        "              restore_from='fresh',\n",
        "              run_name=name,\n",
        "              sample_every=250, #generate sample text every 250 steps\n",
        "              sample_length=1023, #sample text has 1023 words\n",
        "              sample_num=1,\n",
        "              save_every=250,\n",
        "              print_every=10, #print the train result every 10 steps\n",
        "              # max_checkpoints=1,\n",
        "              only_train_transformer_layers=False,\n",
        "              optimizer='adam', overwrite=True\n",
        "              )\n",
        "gpt2.copy_checkpoint_to_gdrive(run_name=name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/gpt_2_simple/src/sample.py:17: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Loading checkpoint models/124M/model.ckpt\n",
            "INFO:tensorflow:Restoring parameters from models/124M/model.ckpt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading dataset...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  1.60it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "dataset has 113765 tokens\n",
            "Training...\n",
            "[10 | 29.19] loss=2.85 avg=2.85\n",
            "[20 | 53.40] loss=2.77 avg=2.81\n",
            "[30 | 76.64] loss=2.67 avg=2.76\n",
            "[40 | 99.76] loss=2.67 avg=2.74\n",
            "[50 | 123.29] loss=2.47 avg=2.69\n",
            "[60 | 146.87] loss=2.58 avg=2.67\n",
            "[70 | 170.24] loss=2.45 avg=2.63\n",
            "[80 | 193.63] loss=2.13 avg=2.57\n",
            "[90 | 217.11] loss=2.27 avg=2.53\n",
            "[100 | 240.62] loss=2.16 avg=2.49\n",
            "[110 | 264.11] loss=2.05 avg=2.45\n",
            "[120 | 287.63] loss=1.84 avg=2.40\n",
            "[130 | 311.11] loss=1.67 avg=2.34\n",
            "[140 | 334.52] loss=1.32 avg=2.26\n",
            "[150 | 357.90] loss=1.38 avg=2.20\n",
            "[160 | 381.29] loss=1.39 avg=2.14\n",
            "[170 | 404.66] loss=0.99 avg=2.07\n",
            "[180 | 428.05] loss=1.11 avg=2.01\n",
            "[190 | 451.51] loss=1.08 avg=1.96\n",
            "[200 | 475.01] loss=0.77 avg=1.89\n",
            "[210 | 498.52] loss=0.79 avg=1.84\n",
            "[220 | 522.02] loss=0.76 avg=1.78\n",
            "[230 | 545.51] loss=0.60 avg=1.72\n",
            "[240 | 569.00] loss=0.88 avg=1.69\n",
            "[250 | 592.47] loss=0.51 avg=1.63\n",
            "Saving checkpoint/HarryPotter/model-250\n",
            "======== SAMPLE 1 ========\n",
            " warn, that's what we do. --We'll show you next year, eh?\" \n",
            "\n",
            "Hagrid chuckled and hung his head. The servant laughed too, but hardly. He looked as though he was listening to some preternaturally brilliant lecture. He had sunk to the floor, gasping for breath, as he shuffled onto his back to get a warm drink. \n",
            "\n",
            "At last, Hagrid managed to get a cool swallow, and the servant shuddered -- it only took a very dark creature to wake him. Hagrid sat back down on the stool and prodded it with his fingers to open a second door. \n",
            "\n",
            "The next chamber was very dark, with only the dead as the only light coming in. Madam Hooch stood before the portrait hole, looking tired and somewhat frightened. Harry tried to shut the door quietly enough, but Hagrid pushed him off his level. \n",
            "\n",
            "\"How do these two get in here?\" he asked, trying to look as though he was dreaming. Harry's mind was racing. Where did the library go? Where had the Dursleys been when the ghost of Uncle Vernon had seen them coming across an unknown being inside a bag? Where had the Muggles been all along? Where had the owls been at this point? The thought made Harry pull the door open. \n",
            "\n",
            "There it was, a very dark and stifling room. A toilet flushed warm blood all over the walls, and Hagrid leaned forward as though he was looking down at the ceiling shaft with a phoenix. \n",
            "\n",
            "\"An' what're you waitin' for me, you old scumbag,\" he murmured, trying to look as though a large, black-haired beast was waiting for him somewhere close behind the locked door. \n",
            "\n",
            "One of Hagrid's cats leapt out of the fireplace and began to graze itself on Hagrid's trousers. \n",
            "\n",
            "Hagrid was rather quiet, staring intently at the cat, which was about to tickle its tail when a second one came rattling about just as suddenly as first. \n",
            "\n",
            "\"Well done, Hagrid,\" said the second one, but it didn't come quickly enough. \n",
            "\n",
            "\"I've got to go, I've got ter do this,\" said the first one. \"Barely five minutes until Professor McGonagall shows up at the Hagrid's.\" \n",
            "\n",
            "\"I'll see her,\" said the second one. \"I hope she's smiling, Hagrid.\" \n",
            "\n",
            "Hagrid leapt at the chance. \"You leaving for the morning?\" he asked Harry nervously. \n",
            "\n",
            "\"I'm not leaving,\" said Harry. \"I've been looking forward to ter do that for a bit.\" \n",
            "\n",
            "\"Come on, boys and girls!\" shouted Hagrid hotly. \"What are you all waiting for?\" \n",
            "\n",
            "Harry walked toward the door, Professor McGonagall following behind him. \n",
            "\n",
            "\"It's locked,\" said Hagrid fiercely. \"Go away and get some more food.\" \n",
            "\n",
            "\"I will,\" said Harry agreed. He dashed back inside and knocked at the door, knocking again. The door was only slightly raised. He pushed it very hard, and a few seconds later it was open. He looked in the little black bookcase and saw a neatly folded note: a cousin of yours who worked here wanted to know what was in it. He slipped it under the note and made his way quickly through the books. \n",
            "\n",
            "There were books in the common room, but not what he was looking for. Hagrid dropped the note over his shoulder and sat down. Harry stared, then he straightened. He wanted to read the title, the little address. No, Hagrid, the address wasn't ever found. \n",
            "\n",
            "Harry opened the door and gasped -- in fact, he strained to see the little book that Uncle Vernon had brought him. A sharp pink toothformed mark where his nose had gone. Pulling out the letter, he read: FRONT PAGE, No. 90, Number Nine Slytherin Club, Barnabas Birthday: Jun. 17, 1797 Character: Harry UGVGRY DURSLEY Professor McGonagall Main desk: Quarters speed Only Rain Can Be Had Astronomical objects in the sky above the Quaffle: Diurnal animals of every description Lights above and below the bedspread (light but invisible to the naked eye) Scales show number and direction of dim Lights above and below the Quaffle: between 0 and 31,001 points The letters Y and Z lower c are ordinary and A-Z u are unusual (see \"About this Quidditch Table\" in the Help>About this Table) Other books in the common room The Quidditch Reference Book (the \"Book\"), as it were, had several pages. The smallest, the -Y in front of the ball and then the letter T under the Quaffle\n",
            "\n",
            "[260 | 630.89] loss=0.38 avg=1.58\n",
            "[270 | 654.52] loss=0.38 avg=1.53\n",
            "[280 | 677.95] loss=0.27 avg=1.48\n",
            "[290 | 701.36] loss=0.26 avg=1.43\n",
            "[300 | 724.85] loss=0.26 avg=1.38\n",
            "[310 | 748.36] loss=0.24 avg=1.34\n",
            "[320 | 771.86] loss=0.18 avg=1.30\n",
            "[330 | 795.37] loss=0.16 avg=1.26\n",
            "[340 | 818.85] loss=0.15 avg=1.22\n",
            "[350 | 842.29] loss=0.20 avg=1.19\n",
            "[360 | 865.73] loss=0.17 avg=1.15\n",
            "[370 | 889.24] loss=0.13 avg=1.12\n",
            "[380 | 912.74] loss=0.11 avg=1.09\n",
            "[390 | 936.24] loss=0.10 avg=1.06\n",
            "[400 | 959.74] loss=0.13 avg=1.03\n",
            "[410 | 983.25] loss=0.15 avg=1.00\n",
            "[420 | 1006.81] loss=0.11 avg=0.98\n",
            "[430 | 1030.35] loss=0.11 avg=0.95\n",
            "[440 | 1053.89] loss=0.10 avg=0.93\n",
            "[450 | 1077.41] loss=0.10 avg=0.91\n",
            "[460 | 1100.92] loss=0.10 avg=0.88\n",
            "[470 | 1124.42] loss=0.09 avg=0.86\n",
            "[480 | 1147.90] loss=0.08 avg=0.84\n",
            "[490 | 1171.40] loss=0.06 avg=0.82\n",
            "[500 | 1194.91] loss=0.07 avg=0.80\n",
            "Saving checkpoint/HarryPotter/model-500\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 38
        },
        "id": "4hEXMlBJ_9QC",
        "outputId": "4841b844-fc5a-46ac-c9b5-878f84aca0ba"
      },
      "source": [
        "%%html\n",
        "<marquee style='width: 30%; color: black;'><b>Run Checkpoint</b></marquee>"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<marquee style='width: 30%; color: black;'><b>Run Checkpoint</b></marquee>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-X5MHyRJ1ZUx"
      },
      "source": [
        "**Do not** run this cell except **checkpoint** is needed. To rerun this cell, **restart the VM first** (Runtime > Restart Runtime). Reimport imports and files is needed. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VaDEITs7pFhR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef5bd776-6108-4b66-a167-8be60c45491a"
      },
      "source": [
        "#Run Checkpoint\n",
        "gpt2.copy_checkpoint_from_gdrive(run_name=name)\n",
        "sess = gpt2.start_tf_sess()\n",
        "gpt2.load_gpt2(sess, run_name=name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading checkpoint checkpoint/HarryPotter/model-500\n",
            "INFO:tensorflow:Restoring parameters from checkpoint/HarryPotter/model-500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3IYClpez8W7f"
      },
      "source": [
        "#parameters\n",
        "gpt2.generate?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pU-ycHMN3Per"
      },
      "source": [
        "# Start generate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FrdUUCvx3a5D"
      },
      "source": [
        "prefix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fk78qtqawer2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9d90ee8-4f44-47c3-93ae-b6d4739741cc"
      },
      "source": [
        "#prefix\n",
        "gpt2.generate(sess, \n",
        "              run_name=name,\n",
        "              length=100,\n",
        "              prefix=\"I love you\"             \n",
        "              )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I love you, Harry.\" \n",
            "\n",
            "\"Not as much as you would like,\" said Ron, who happened to be sitting next to Ginny. \n",
            "\n",
            "\"I'm not as good as you,\" said Harry, who really didn't need reminding that he was just a month into this thing -- it had been years since he'd had a day off, and he still couldn't remember the last time. He'd forgotten that the Dursleys had tormented him for years. \n",
            "\n",
            "\"You\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTn7pUhT3dL4"
      },
      "source": [
        "temperature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uz3if7O63hmO",
        "outputId": "9e9172bc-78d0-44dc-a9fa-af17ce5a605f"
      },
      "source": [
        "#temperature\n",
        "print(\"temperature = 0.7: \\n\")\n",
        "gpt2.generate(sess,\n",
        "              run_name=name,\n",
        "              length= 100,\n",
        "              temperature =  0.7\n",
        "              )\n",
        "print(\"\\n temperature = 1.5: \\n\")\n",
        "gpt2.generate(sess,\n",
        "              run_name=name,\n",
        "              length= 100,\n",
        "              temperature =  1.5\n",
        "              )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "temperature = 0.7: \n",
            "\n",
            "You have come to take me off the hook, Madam Pomfrey,\" said Dumbledore. \"And you have not informed me that you have come to take me off the grounds?\" \n",
            "\n",
            "\"Dunno,\" said Harry, \"I suppose you thought you'd be able to tell me what to stop me from going to Hogwarts, Harry?\" \n",
            "\n",
            "\"Malfoy, yes,\" said Dumbledore, breathing heavily and sitting back down on his plate. \"He was on Harry's tail when\n",
            "\n",
            " temperature = 1.5: \n",
            "\n",
            "Kept modest, Constance spent as much time in her tidy wooden house as cats did on their dirty beds. She had a very good idea what part of the house they were in; she watched them walk behind their century-old drumming cup, questions running their insides like mad as they were: \"On Mrs. Norris's front step, Defense Against the Dark -- faster than two realms!\" Diagon Alley nailed her to a heavy oak table, which she sank back down against, her\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLpdMdxA3gNT"
      },
      "source": [
        "Unrelated strings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VHeyt3wFMj6n",
        "outputId": "83ddd425-f233-4afb-d84d-e169ba7fe3b7"
      },
      "source": [
        "gpt2.generate(sess,\n",
        "              run_name= name,\n",
        "              prefix = \"Pikachu!\",\n",
        "              length = 100\n",
        "              )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pikachu! Switching to Flaming Lips!\" \n",
            "\n",
            "Harry heard the Flaming Lips screech to a halt a few feet away. He pointed down a flight of steps that were the only sensible course. He asked, but they said he wasn't going to climb -- now was the time to make a choice -- and they climbed -- Harry turned his back on the forest floor and clapped his hands. They listened to the music again, which was a comforting crescendo. \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VOrndX2ONGQ1",
        "outputId": "51ec1137-6fa4-44fc-91a7-20de4b364b32"
      },
      "source": [
        "gpt2.generate(sess,\n",
        "              run_name= name,\n",
        "              prefix = \"Pikachu!\",\n",
        "              length = 300,\n",
        "              )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pikachu! I've found you!\" \n",
            "\n",
            "\"PUPPETLIUM!\" \n",
            "\n",
            "\"Firenze! Firenze! Firenze! Fire!\" \n",
            "\n",
            "\"Hagrid! Look at you all last night!\" pipped Pinsent. \n",
            "\n",
            "\"I've got to ask Peeves, he's got a problem --\" \n",
            "\n",
            "\"You never had a problem since you were born, Peeves, where have you been?\" \n",
            "\n",
            "\"I've got to ask Fred, he's got a problem --\" \n",
            "\n",
            "\"There's more, this is all, you mustn't go wandering around the school! Everyone's running for their lives everywhere!\" said Peeves. \n",
            "\n",
            "\"You know what everyone else's going to be doing?\" \n",
            "\n",
            "\"Yeah -- everyone's jumping off buildings -- jumping off trains -- all this time!\" said Peeves, and a train of sparks was flying out of a window just as Harry and Ron were being led off the train by Peeves to the ground. \n",
            "\n",
            "\"Oh, go on, Peeves, you should have done a better job of hiding behind the girls' bathroom doors!\" said Ron. \n",
            "\n",
            "\"What?\" panted Peeves, and Harry and Ron rolled onto their backs. \n",
            "\n",
            "\"You've got to get out!\" said Harry, and they did. They had never in a million years wanted to\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 38
        },
        "id": "MFJpgDBHNd-K",
        "outputId": "430fe3f7-7282-46fc-c138-9b6786103f58"
      },
      "source": [
        "%%html\n",
        "<marquee style='width: 30%; color: black;'><b>DEMO</b></marquee>"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<marquee style='width: 30%; color: black;'><b>DEMO</b></marquee>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lw_jdn9c3kL7"
      },
      "source": [
        "DEMO"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6qd8EadBCWvv",
        "outputId": "9d6081e8-915e-40f2-eab9-3f9336f3a169"
      },
      "source": [
        "#Demo\n",
        "\n",
        "prefix = \"Doomsday\" #@param {type:\"string\"}\n",
        "temperature =   0.8#@param {type: \"number\"}\n",
        "length = 318 #@param {type:\"slider\" , min : 10, max : 500}\n",
        "k = 37 #@param {type:\"slider\" , min : 0, max : 50}\n",
        "\n",
        "# top_k=0 : Integer value controlling diversity\n",
        "\n",
        "gpt2.generate(sess,\n",
        "              run_name=name,\n",
        "              length= length,\n",
        "              prefix = prefix,\n",
        "              temperature = temperature,\n",
        "              top_k = k\n",
        "              )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Doomsday clockwork like that. It'll be five minutes before the vault doors open again.\" \n",
            "\n",
            "Harry leaned back quickly so that Ron was standing on top of him. \n",
            "\n",
            "\"Ron, you want to watch the mirror!\" \n",
            "\n",
            "\"I do.\" \n",
            "\n",
            "\"How does it look?\" \n",
            "\n",
            "\"It's a lot like what you've seen -- the Great Pumpkin, Daffodil, the Madam Malkin. Look -- look!\" \n",
            "\n",
            "\"There's a note!\" \n",
            "\n",
            "\"Harry!\" \n",
            "\n",
            "Harry saw Ron's hand close as though it was on the note; it crept into his pocket and then Harry felt a hand curl around his waist. \n",
            "\n",
            "\"Here we go!\" he said, taking out the letterhead from Bagshot. \"Now, don't ask me what I'm talking about, it's not a camera, it's a piece of cake.\" \n",
            "\n",
            "Ron read the letter quickly, the page before him twinkling in the mist. \n",
            "\n",
            "\"P-P-Petunia!\" \n",
            "\n",
            "\"Who's to say she isn't checking in with the Ministry of Magic?\" said Harry. \n",
            "\n",
            "\"We've all seen the Dursleys' faces -- look --\" \n",
            "\n",
            "Harry looked. \n",
            "\n",
            "\" -- see Petunia!\" \n",
            "\n",
            "\"Mommy wouldn't talk about that.\" \n",
            "\n",
            "\"Oh, that's exactly the problem.\" \n",
            "\n",
            "They walked straight past a mossy tree stump. \n",
            "\n",
            "Harry could\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxNtRlEn3nve"
      },
      "source": [
        "## Thank you for reading our code!"
      ]
    }
  ]
}